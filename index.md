---
layout: default
---

<img align="left" width="200" src="/assets/mw.jpg" style="border-radius: 20%; margin: 0px 60px 20px 0px;"/>

I work at Tesla as a software engineer on the Autopilot team.
Previously, I was a masters student in computer science at the [University of 
British Columbia (UBC)](https://www.cs.ubc.ca/), working on robotics and reinforcement
\+ deep learning research, advised by [Michiel van de Panne](https://www.cs.ubc.ca/~van/).  Before that, I worked on similar research for my undergraduate 
thesis at the University of Utah (2019) as a member of the [LL4MA lab](https://robot-learning.cs.utah.edu/), advised by [Tucker Hermans](https://robot-learning.cs.utah.edu/thermans). 

[CV](/assets/cv.pdf)
/ [GitHub](https://github.com/matwilso)
/ [Twitter](https://twitter.com/matwilso) 
/ [LinkedIn](https://www.linkedin.com/in/matthew-wilson-916505104/)
/ [Stack Overflow](https://stackoverflow.com/users/7211137/matwilso)


### News
- Aug 2021: I joined Tesla Autopilot as a software engineer
- Apr 2021: [boxLCD paper](/assets/boxLCD_iclr2021_workshop.pdf) was accepted to the ICLR 2021 Workshop on [Deep Learning for Simulation (SimDL)](https://simdl.github.io/)!
- Feb 2021: I released [boxLCD](https://github.com/matwilso/boxLCD) and [generative_models](https://github.com/matwilso/generative_models) repos, and new blog posts on the [Future of Robot Learning](/robot-future) and [Learned Simulators](/learned-sims)
- Nov 2019: Our work won the Best System Paper Award at [CoRL 2019!](https://sites.google.com/robot-learning.org/corl2019) 
- Sep 2019: Our work on "Learning to Manipulate Object Collections Using Grounded State Representations" was accepted to the Conference on Robot Learning ([CoRL](https://www.robot-learning.org/)) 2019!
- Jun 2018: I wrote up an answer to a [stackoverflow question on PPO (Proximal Policy Optimization)](https://stackoverflow.com/questions/46422845/what-is-the-way-to-understand-proximal-policy-optimization-algorithm-in-rl/50663200#50663200)


# Research Projects
<style>
.static {
  background: white;
}
.static:hover {
  opacity:0;
}
.container {
    position: relative;
    width: 35%;
}

.image {
    position: absolute;
}
</style>


<br>

<div class="container">
    <div class="mage">
    <img class="active" align="left" src="/assets/robot/lcd_sideside.gif" style="border-radius: 0%; margin: 0px 10px 30px 0px;"/>
    </div>
    <div class="image">
    <img class="static" align="left" src="/assets/robot/lcd_sideside.png" style="border-radius: 0%; margin: 0px 10px 30px 0px;"/>
    </div>
</div>
<div style="font-size: 18px; font-weight: bold;">boxLCD: A Simple Testbed for Learned Simulator and World Model Research</div>
ICLR 2021  [SimDL Workshop](https://simdl.github.io/overview) <br>
[[GitHub Project](https://github.com/matwilso/boxLCD)] [[Blog](robot-future) [Posts](/learned-sims)][[Paper](/assets/boxLCD_iclr2021_workshop.pdf)]

<br>



<img align="left" width="35%" src="/assets/task.png" style="border-radius: 0%; margin: 0px 10px 30px 0px;"/>
<div style="font-size: 18px; font-weight: bold;">Learning to Manipulate Object Collections<br>Using Grounded State Representations</div>
Matthew Wilson, Tucker Hermans <br>
[CoRL 2019](https://www.robot-learning.org) (Oral, Best System Paper) <br>
[[arXiv](https://arxiv.org/abs/1909.07876)] [[Project Page](/projects/object_collections)]  [[Code](https://github.com/matwilso/object_collections)]

